{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib imported successfully with Agg backend!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use a non-interactive backend\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"Matplotlib imported successfully with Agg backend!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuitive Supervised Learning for Flood Prediction\n",
    "\n",
    "This notebook demonstrates how we can use machine learning to predict flood probability based on various environmental and human factors. We'll walk through each step, explaining how it relates to our flood prediction goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we import the tools we need for our flood prediction project\n",
    "import pandas as pd  # For handling our flood data\n",
    "import numpy as np  # For numerical operations\n",
    "from sklearn.model_selection import train_test_split  # To split our flood data\n",
    "from sklearn.ensemble import RandomForestRegressor  # Our flood prediction model\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # To evaluate our flood predictions\n",
    "\n",
    "import matplotlib.pyplot as plt  # For visualizing flood risk factors\n",
    "import seaborn as sns  # For prettier visualizations\n",
    "\n",
    "# We set a random seed to make our flood predictions reproducible\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading and Exploring Our Flood Data\n",
    "\n",
    "First, we need to load and examine our flood-related data to understand what information we have to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the first few rows of our flood data:\n",
      "   MonsoonIntensity  TopographyDrainage  RiverManagement  Deforestation  \\\n",
      "0                 3                   8                6              6   \n",
      "1                 8                   4                5              7   \n",
      "2                 3                  10                4              1   \n",
      "3                 4                   4                2              7   \n",
      "4                 3                   7                5              2   \n",
      "\n",
      "   Urbanization  ClimateChange  DamsQuality  Siltation  AgriculturalPractices  \\\n",
      "0             4              4            6          2                      3   \n",
      "1             7              9            1          5                      5   \n",
      "2             7              5            4          7                      4   \n",
      "3             3              4            1          4                      6   \n",
      "4             5              8            5          2                      7   \n",
      "\n",
      "   Encroachments  ...  DrainageSystems  CoastalVulnerability  Landslides  \\\n",
      "0              2  ...               10                     7           4   \n",
      "1              4  ...                9                     2           6   \n",
      "2              9  ...                7                     4           4   \n",
      "3              4  ...                4                     2           6   \n",
      "4              5  ...                7                     6           5   \n",
      "\n",
      "   Watersheds  DeterioratingInfrastructure  PopulationScore  WetlandLoss  \\\n",
      "0           2                            3                4            3   \n",
      "1           2                            1                1            9   \n",
      "2           8                            6                1            8   \n",
      "3           6                            8                8            6   \n",
      "4           3                            3                4            4   \n",
      "\n",
      "   InadequatePlanning  PoliticalFactors  FloodProbability  \n",
      "0                   2                 6             0.450  \n",
      "1                   1                 3             0.475  \n",
      "2                   3                 6             0.515  \n",
      "3                   6                10             0.520  \n",
      "4                   3                 4             0.475  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "Here's some information about our flood dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   MonsoonIntensity                 50000 non-null  int64  \n",
      " 1   TopographyDrainage               50000 non-null  int64  \n",
      " 2   RiverManagement                  50000 non-null  int64  \n",
      " 3   Deforestation                    50000 non-null  int64  \n",
      " 4   Urbanization                     50000 non-null  int64  \n",
      " 5   ClimateChange                    50000 non-null  int64  \n",
      " 6   DamsQuality                      50000 non-null  int64  \n",
      " 7   Siltation                        50000 non-null  int64  \n",
      " 8   AgriculturalPractices            50000 non-null  int64  \n",
      " 9   Encroachments                    50000 non-null  int64  \n",
      " 10  IneffectiveDisasterPreparedness  50000 non-null  int64  \n",
      " 11  DrainageSystems                  50000 non-null  int64  \n",
      " 12  CoastalVulnerability             50000 non-null  int64  \n",
      " 13  Landslides                       50000 non-null  int64  \n",
      " 14  Watersheds                       50000 non-null  int64  \n",
      " 15  DeterioratingInfrastructure      50000 non-null  int64  \n",
      " 16  PopulationScore                  50000 non-null  int64  \n",
      " 17  WetlandLoss                      50000 non-null  int64  \n",
      " 18  InadequatePlanning               50000 non-null  int64  \n",
      " 19  PoliticalFactors                 50000 non-null  int64  \n",
      " 20  FloodProbability                 50000 non-null  float64\n",
      "dtypes: float64(1), int64(20)\n",
      "memory usage: 8.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the flood data from our CSV file\n",
    "flood_data = pd.read_csv('flood_kaggle.csv')\n",
    "\n",
    "# Let's look at the first few rows of our flood data\n",
    "print(\"Here are the first few rows of our flood data:\")\n",
    "print(flood_data.head())\n",
    "\n",
    "# And get some basic information about our flood dataset\n",
    "print(\"\\nHere's some information about our flood dataset:\")\n",
    "print(flood_data.info())\n",
    "\n",
    "# This gives us an overview of our dataset. We can see all the factors that might influence flood probability,\n",
    "# like MonsoonIntensity, TopographyDrainage, etc., and our target variable 'FloodProbability' at the end.\n",
    "# Understanding these factors is crucial for predicting flood risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preparing Our Flood Data\n",
    "\n",
    "Now that we've loaded our data, we need to prepare it for our machine learning model. We'll split our data into two parts:\n",
    "1. The features (X) - all the factors that might influence flooding\n",
    "2. The target (y) - the flood probability we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 40000 flood scenarios to train our model\n",
      "And 10000 flood scenarios to test it\n"
     ]
    }
   ],
   "source": [
    "# Separate our flood risk factors (X) and flood probability (y)\n",
    "X = flood_data.drop('FloodProbability', axis=1)  # All columns except FloodProbability\n",
    "y = flood_data['FloodProbability']  # Just the FloodProbability column\n",
    "\n",
    "# Now we split our data into training and testing sets\n",
    "# We'll use 80% of the data to train our flood prediction model, and 20% to test it\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"We have {X_train.shape[0]} flood scenarios to train our model\")\n",
    "print(f\"And {X_test.shape[0]} flood scenarios to test it\")\n",
    "\n",
    "# This split allows us to train our model on one set of flood data and then test how well it performs on data it hasn't seen before.\n",
    "# This helps us understand if our model can generalize to new flood scenarios, which is crucial for predicting future flood risks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Training Our Flood Prediction Model\n",
    "\n",
    "Now we'll use a Random Forest model to learn patterns from our training data. Think of this like the model studying many examples of past flood scenarios to understand what factors lead to higher flood probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our flood prediction model has finished learning from the training data!\n"
     ]
    }
   ],
   "source": [
    "# Create our Random Forest model for flood prediction\n",
    "# n_estimators=100 means it will create 100 decision trees to make its predictions\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on our flood data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Our flood prediction model has finished learning from the training data!\")\n",
    "\n",
    "# The model has now learned patterns from the training data. It's like it has studied many past flood scenarios\n",
    "# and understands how different factors (like monsoon intensity, topography, etc.) relate to flood probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluating Our Flood Prediction Model\n",
    "\n",
    "Now that our model has learned, let's see how well it can predict flood probabilities for scenarios it hasn't seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0007\n",
      "R-squared Score: 0.7295\n"
     ]
    }
   ],
   "source": [
    "# Use our trained model to make flood probability predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate how well our predictions match the actual flood probabilities\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared Score: {r2:.4f}\")\n",
    "\n",
    "# The Mean Squared Error (MSE) tells us how far off our flood predictions are on average. Lower is better.\n",
    "# The R-squared score tells us how well our model explains the variability in flood probability. Closer to 1 is better.\n",
    "# These metrics help us understand how reliable our flood predictions might be for new areas or future scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Understanding Important Factors for Flood Prediction\n",
    "\n",
    "One of the benefits of our model is that it can tell us which factors are most important in predicting flood probability. This can help focus flood prevention efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most important factors for predicting flood probability are:\n",
      "TopographyDrainage: 0.0530\n",
      "DamsQuality: 0.0528\n",
      "PoliticalFactors: 0.0524\n",
      "IneffectiveDisasterPreparedness: 0.0516\n",
      "PopulationScore: 0.0516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bobby\\AppData\\Local\\Temp\\ipykernel_5992\\3703485671.py:15: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Get the importance of each flood risk factor\n",
    "feature_importance = model.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "# Sort flood risk factors by importance\n",
    "feature_importance_sorted = sorted(zip(feature_importance, features), reverse=True)\n",
    "\n",
    "# Create a bar chart of flood risk factor importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=[imp for imp, _ in feature_importance_sorted], \n",
    "            y=[feat for _, feat in feature_importance_sorted])\n",
    "plt.title(\"Which Factors Are Most Important for Predicting Floods?\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the top 5 most important flood risk factors\n",
    "print(\"The 5 most important factors for predicting flood probability are:\")\n",
    "for imp, feat in feature_importance_sorted[:5]:\n",
    "    print(f\"{feat}: {imp:.4f}\")\n",
    "\n",
    "# This analysis helps us understand which factors contribute most to flood risk.\n",
    "# It could guide where to focus flood prevention efforts or what to monitor most closely for early warning systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 1.1059953150715025e-31, R²: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize and train the Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Linear Regression - MSE: {mse}, R²: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bobby\\AppData\\Local\\Temp\\ipykernel_5992\\561133465.py:11: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot for predicted vs actual values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5, label=\"Predictions\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"Perfect Fit\")\n",
    "plt.title(\"Linear Regression: Predicted vs Actual Flood Probabilities\")\n",
    "plt.xlabel(\"Actual Flood Probability\")\n",
    "plt.ylabel(\"Predicted Flood Probability\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig(\"linear_regression_actual_vs_predicted.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - MSE: 0.0006917651559999998, R²: 0.7222480062226527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest - MSE: {mse_rf}, R²: {r2_rf}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bobby\\AppData\\Local\\Temp\\ipykernel_5992\\351058619.py:12: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot for predicted vs actual values (Random Forest)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5, label=\"Predictions\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label=\"Perfect Fit\")\n",
    "plt.title(\"Random Forest: Predicted vs Actual Flood Probabilities\")\n",
    "plt.xlabel(\"Actual Flood Probability\")\n",
    "plt.ylabel(\"Predicted Flood Probability\")\n",
    "plt.legend()\n",
    "plt.savefig(\"random_forest_actual_vs_predicted.png\")  # Save the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyQt5 in c:\\users\\bobby\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (5.15.11)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.15 in c:\\users\\bobby\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from PyQt5) (12.16.0)\n",
      "Requirement already satisfied: PyQt5-Qt5<5.16.0,>=5.15.2 in c:\\users\\bobby\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from PyQt5) (5.15.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\bobby\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - MSE: 0.0002371374625304009, R²: 0.9047864691567092\n"
     ]
    }
   ],
   "source": [
    "!pip install PyQt5\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "xgb_model = XGBRegressor(n_estimators=50, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost - MSE: {mse_xgb}, R²: {r2_xgb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset (adjust file name if needed)\n",
    "kaggle_data = pd.read_csv('flood_kaggle.csv')\n",
    "\n",
    "# Define the input (X) and target variable (Y)\n",
    "Y_kaggle = kaggle_data['FloodProbability']  # Ensure this column exists in your dataset\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation = kaggle_data.corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.savefig(\"feature_correlation_heatmap.png\")  # Save the plot as an image\n",
    "plt.close()  # Close the plot to free memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Feature importance for Random Forest\n",
    "feature_importance = rf_model.feature_importances_\n",
    "features = X_train.columns\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.title(\"Feature Importance (Random Forest)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.savefig(\"random_forest_feature_importance.png\")  # Save the plot\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "kaggle_data = pd.read_csv('flood_kaggle.csv')\n",
    "Y_kaggle = kaggle_data['FloodProbability']\n",
    "\n",
    "kaggle_data['Interaction_Topography_Dams'] = kaggle_data['TopographyDrainage'] * kaggle_data['DamsQuality']\n",
    "\n",
    "X_interaction = kaggle_data.iloc[:, 1:14].copy()\n",
    "X_interaction['Interaction_Topography_Dams'] = kaggle_data['Interaction_Topography_Dams']\n",
    "\n",
    "X_train_int, X_test_int, y_train_int, y_test_int = train_test_split(X_interaction, Y_kaggle, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "rf_model.fit(X_train_int, y_train_int)\n",
    "\n",
    "y_pred_int = rf_model.predict(X_test_int)\n",
    "mse_int = mean_squared_error(y_test_int, y_pred_int)\n",
    "r2_int = r2_score(y_test_int, y_pred_int)\n",
    "\n",
    "metrics = {'Before': [mse_rf, r2_rf], 'After': [mse_int, r2_int]}\n",
    "categories = ['MSE', 'R²']\n",
    "metrics_df = pd.DataFrame(metrics, index=categories)\n",
    "\n",
    "metrics_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title(\"Model Performance Before and After Interaction Terms\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.legend(title=\"Model\")\n",
    "plt.savefig(\"model_performance_interaction_terms.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Interaction_Topography_Dams\n",
    "plt.figure(figsize=(8, 6))\n",
    "kaggle_data['Interaction_Topography_Dams'].hist(bins=30, color='lightgreen')\n",
    "plt.title(\"Distribution of Interaction Term: TopographyDrainage * DamsQuality\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"interaction_term_distribution.png\")  # Save the plot\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best Score: 0.7236758283465475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model performance\n",
    "print(f\"Best Parameters: {grid_search_rf.best_params_}\")\n",
    "print(f\"Best Score: {grid_search_rf.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Best Score: 0.9560455015270932\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the model\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid_xgb, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model performance\n",
    "print(f\"Best Parameters: {grid_search_xgb.best_params_}\")\n",
    "print(f\"Best Score: {grid_search_xgb.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model from GridSearchCV\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred_rf_best = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate MSE and R² for the best model\n",
    "best_mse_rf = mean_squared_error(y_test, y_pred_rf_best)\n",
    "best_r2_rf = r2_score(y_test, y_pred_rf_best)\n",
    "\n",
    "# Now proceed to your metrics dictionary\n",
    "metrics = {'Before': [mse_rf, r2_rf], 'After': [best_mse_rf, best_r2_rf]}\n",
    "categories = ['MSE', 'R²']\n",
    "metrics_df = pd.DataFrame(metrics, index=categories)\n",
    "\n",
    "metrics_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title(\"Performance Comparison Before and After Hyperparameter Tuning\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.legend(title=\"Model\")\n",
    "plt.savefig(\"performance_comparison_tuning.png\")\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We've now built a model that can predict flood probability based on various environmental and human factors. This model could be used to:\n",
    "1. Estimate flood risk for new areas\n",
    "2. Identify the most critical factors contributing to flood risk\n",
    "3. Guide decision-making for flood prevention and preparedness\n",
    "\n",
    "Remember, this is a simplified model and real-world flood prediction is very complex. But this gives us a starting point for understanding and predicting flood risks. As you continue your project, you might want to consider:\n",
    "- Collecting more detailed local data to improve predictions\n",
    "- Incorporating time-based data to predict flood risks over time\n",
    "- Exploring other machine learning models to see if they perform better\n",
    "- Creating a user-friendly interface for local authorities to use these predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
